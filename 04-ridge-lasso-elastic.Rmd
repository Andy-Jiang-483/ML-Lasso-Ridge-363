---
title: "Lab 04 Ridge, Lasso, Elastic Net"
author: "Andy Jiang"
date: "2020-03-05"
output: html_document
---

### Load packages

```{r load-packages, message = FALSE, warning = FALSE}
library(tidyverse) 
library(tidymodels)
```

### Exercise 1

```{r split dataset into two}
music<- read.csv("music.csv",header = TRUE)

set.seed(7)

music_split <- initial_split(music, prop=0.5)
music_split

music_test <- testing(music_split)

music_train <- training(music_split)
```

As we can see, there are 73 variables in both the training and the testing dataset. Both have 250 observations each. 

### Exercise 2

```{r fitting linear model on lat}

lm_spec <-
  linear_reg()%>%
  set_engine(engine = "lm")
lm_spec
ols_train <- fit(lm_spec,
                 lat~.,
                 data = music_train)

ols_train
lat_pred<-ols_train %>%
  predict(new_data = music_test)%>%
  bind_cols(music_test)
lat_pred %>%
  rmse(truth=lat,estimate=.pred)


```

The testing root men squared error obtained is 18.616

### Exercise 3



```{r finding appropriate penalty in the 10s neighborhood}
set.seed(7)
music_cv <- vfold_cv(music_train, 10)
ridge_spec <- linear_reg(penalty = tune(), mixture = 0)%>%
  set_engine("glmnet")

rec <- recipe(lat ~., data = music_train)%>%
  step_scale(all_predictors())



grid<-expand_grid(penalty = seq(0,100, by =10))

tuning <- tune_grid(ridge_spec,
                    preprocessor = rec,
                    grid = grid,
                    resamples = music_cv)

tuning %>%
  collect_metrics()%>%
  filter(.metric== "rmse")%>%
  arrange(mean)

```
Based on the table above, we can see that when the penalty is between 10 -20, the rmse is the lowest. Thus, we will repeat the tuning process to choose a penalty between 10-20. 

```{r locate penalty}
grid = expand_grid(penalty = seq(10,20, by =1))
tuning <- tune_grid(ridge_spec,
                    preprocessor = rec,
                    grid = grid,
                    resamples = music_cv)

tuning%>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  arrange(mean)
```

It appears that when $\lambda = 12$ the test rmse is the smallest. The test rmse is 17.546. I will choose $\lambda$ to be 12, because this is when the test rmse become the smallest. 












