---
title: "Lab 04 Ridge, Lasso, Elastic Net"
author: "Andy Jiang"
date: "2020-03-05"
output: html_document
---

### Load packages

```{r load-packages, message = FALSE, warning = FALSE}
library(tidyverse) 
library(tidymodels)
```

### Exercise 1

```{r split-dataset-into-two}
music<- read.csv("music.csv",header = TRUE)

set.seed(7)

music_split <- initial_split(music, prop=0.5)
music_split

music_test <- testing(music_split)

music_train <- training(music_split)
```

As we can see, there are 73 variables in both the training and the testing dataset. Both have 250 observations each. 

### Exercise 2

```{r fitting-linear-model-on-lat}

lm_spec <-
  linear_reg()%>%
  set_engine(engine = "lm")
lm_spec
ols_train <- fit(lm_spec,
                 lat~.,
                 data = music_train)

ols_train
lat_pred<-ols_train %>%
  predict(new_data = music_test)%>%
  bind_cols(music_test)
lat_pred %>%
  rmse(truth=lat,estimate=.pred)


```

The testing root men squared error obtained is 18.616

### Exercise 3

$@$ for 3-5 how do i use the testing portion of the initially split data. 


```{r finding-appropriate-penalty-in-the-10s-neighborhood}
set.seed(7)
music_cv <- vfold_cv(music_train, 10)
ridge_spec <- linear_reg(penalty = tune(), mixture = 0)%>%
  set_engine("glmnet")

rec <- recipe(lat ~., data = music_train)%>%
  step_scale(all_predictors())



grid<-expand_grid(penalty = seq(0,100, by =10))

tuning <- tune_grid(ridge_spec,
                    preprocessor = rec,
                    grid = grid,
                    resamples = music_cv)

tuning %>%
  collect_metrics()%>%
  filter(.metric== "rmse")%>%
  arrange(mean)

```
Based on the table above, we can see that when the penalty is between 10 -20, the rmse is the lowest. Thus, we will repeat the tuning process to choose a penalty between 10-20. 

```{r locate-penalty}
grid = expand_grid(penalty = seq(10,20, by =1))
tuning <- tune_grid(ridge_spec,
                    preprocessor = rec,
                    grid = grid,
                    resamples = music_cv)

tuning%>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  arrange(mean)



```

```{r get-rmse}
ridge_spec <- linear_reg(penalty = 12, mixture = 0)%>%
  set_engine("glmnet")

ridge_fit <- fit(ridge_spec, 
                 lat~.,
                 data = music_train)

ridge_pred <- ridge_fit %>%
  predict(new_data = music_test)%>%
  bind_cols(music_test)

ridge_pred %>%
  rmse(truth = lat, estimate = .pred)
```

When $\lambda$ is 12, the test root mean squared error is the smallest. Thus, we choose $\lambda$ to be 12. The test RMSE is 16.467 

###Exercise 4

```{r choosing-penalty-for-lasso}
set.seed(7)

lasso_spec <- linear_reg(penalty = tune(), mixture = 1)%>%
  set_engine("glmnet")

grid <- expand_grid(penalty = seq(0,100, by = 1))

results <- tune_grid(lasso_spec, 
                    rec,
                    grid = grid, 
                    resamples = music_cv)
results %>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  arrange(mean)

```

```{r get-rmse2}
lasso_spec <- linear_reg(penalty = 1, mixture = 1)%>%
  set_engine("glmnet")
lasso_fit <- fit(lasso_spec,
                 lat ~.,
                 data = music_train)
lasso_pred <- lasso_fit %>%
  predict(new_data = music_test)%>%
  bind_cols(music_test)

lasso_pred%>%
  rmse(truth=lat, estimate =.pred)
```


It appears that when the penalty is 1, the test rmse is the lowest. The test rmse when the penalty is 1 is 16.513

###Exercise 5

```{r elastic-net-graph-with-penalty-is-[0,100]}
set.seed(7)
elasticNet_spec <- linear_reg(penalty = tune(), mixture = tune())%>%
  set_engine("glmnet")

grid <- expand_grid(penalty=seq(0,100, by = 10), mixture = seq(0,1,by = 0.1))

results <- tune_grid(elasticNet_spec, 
                    rec,
                    grid = grid, 
                    resamples = music_cv)
results %>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  ggplot(aes(penalty, mean, color = factor(mixture), group = factor(mixture))) + 
  geom_line() + 
  geom_point()+
  labs(y = "RMSE")


```

As we can see from the graph, when the $\lambda$ is less than 25, all 10 models with differnet $\alpha$ level yield the lowest testing RMSE. Thus, we will restrict $\lambda$ to [0,25]. 


```{r elastic-net-graph-with-penalty-is-[0,20]}
grid <- expand_grid(penalty=seq(0,20, by = 1), mixture = seq(0,1,by = 0.1))

results <- tune_grid(elasticNet_spec, 
                     preprocessor = rec,
                     grid = grid, 
                     resamples = music_cv)



results %>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  ggplot(aes(penalty, mean, color = factor(mixture), group = factor(mixture))) + 
  geom_line() + 
  geom_point()+
  labs(y = "RMSE")

```

As we can see from the graph, the lowest testing rmse occured when the penalty is below 5. Thus, we will restrict our search to $\lambda\in[0,5]$

```{r elastic-net-graph-with-penalty-is-[0,5]}
grid <- expand_grid(penalty=seq(0,5, by = 1), mixture = seq(0,1,by = 0.1))

results <- tune_grid(elasticNet_spec, 
                     preprocessor = rec,
                     grid = grid, 
                     resamples = music_cv)



results %>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  ggplot(aes(penalty, mean, color = factor(mixture), group = factor(mixture))) + 
  geom_line() + 
  geom_point()+
  labs(y = "RMSE")

results %>%
  collect_metrics()%>%
  filter(.metric == "rmse")%>%
  arrange(mean)
```

```{r get-rmse3}
elasticNet_spec <- linear_reg(penalty = 1, mixture = 1)%>%
  set_engine("glmnet")

elasticNet_fit <- fit(elasticNet_spec,
                      lat~.,
                      data = music_train)

elasticNet_pred <- elasticNet_fit %>%
  predict(new_data = music_test)%>%
  bind_cols(music_test)

elasticNet_pred%>%
  rmse(truth = lat, estimate = .pred)
```


By examing the table, we can see that when $\lambda$ is 1 and when $\alpha$ is 1, the elastic net yields the lowest test rmse of 16.513. 


### Exercise 6

The test RMSE for linear regression is 18.62
The test RMSE for ridge is 16.467
The test RMSE for lasso is 16.513

In the previous exercise, our elastic net has a test rmse of 16.513. RMSE can be used to measure model fit. As the square root of a variance, RMSE illustrates the standard deviation of the unexplained variance. 16.513 is relatively low, thus, it shows that our model fit is relatively good. It means that the square root of the average of squared differences between our predicted latitude and the actual latitude is 16.513 degrees. 

There isn't much differences among the 4 different approaches. 



